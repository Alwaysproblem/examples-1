{
  "task": "pretraining",
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 128,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "num_attention_heads": 2,
  "num_hidden_layers": 2,
  "hidden_layers_per_stage": 2,
  "type_vocab_size": 2,
  "vocab_size": 30528,
  "seq_length": 128,
  "batch_size": 8,
  "batches_per_step": 1,
  "epochs": 1,
  "max_predictions_per_seq": 20,
  "base_learning_rate": 0.0004,
  "lr_schedule": "natural_exponential",
  "lr_schedule_by_step":{
    "0": 0.0004
  },
  "loss_scaling": 1.0,

  "optimiser": "adamw",
  "parallell_io_threads": 16,
  "pipeline_depth": 8,
  "pipeline_schedule": "Grouped",
  "replicas": 1,
  "precision": "16",
  "seed": 1234,
  "steps_per_ckpts": 100,
  "steps_per_logs": 1,
  "warmup": 128,
  "decay_steps": 512,
  "decay_rate": 0.051,
  "weight_decay": 0.0003,
  "disable_graph_outlining": false,
  "restoring":false,
  "no_logs": false,
  "do_validation":false,
  "do_train":true,
  "available_memory_proportion":0.6,
  "embeddings_placement": "same_as_hidden_layers",

  "checkpoint_path": "./checkpoint/phase1",
  "checkpoint_model":"./checkpoint/phase1/model"
}
