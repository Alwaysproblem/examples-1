{
  "task": "pretraining",
  "attention_probs_dropout_prob": 0.0,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 128,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "num_attention_heads": 16,
  "num_hidden_layers": 1,
  "hidden_layers_per_stage": [1],
  "type_vocab_size": 2,
  "vocab_size": 30528,
  "seq_length": 128,
  "batch_size": 2,
  "batches_per_step": 1,
  "steps": 10,
  "warmup": 0.01,
  "max_predictions_per_seq": 20,
  "base_learning_rate": 0.01,
  "lr_schedule": "polynomial_decay",
  "loss_scaling": 1,
  "optimiser": "lamb",
  "pipeline_depth": 80,
  "parallell_io_threads": 16,
  "pipeline_schedule": "Grouped",
  "replicas": 1,
  "precision": "32",
  "seed": 1234,
  "logits_matmul_serialization_factor": 6,
  "scheduler": "Clustering",
  "steps_per_ckpts": 100,
  "steps_per_logs": 1,
  "warmup_epochs": 0,
  "decay_steps": 512,
  "decay_rate": 0.051,
  "weight_decay": 0.01,
  "disable_graph_outlining": false,
  "restoring": false,
  "no_logs": false,
  "do_validation": false,
  "do_train": true,
  "ipu_function": true,
  "available_memory_proportion": 0.11,
  "partials_type": "half",
  "embeddings_placement": "same_as_hidden_layers",
  "reduction_type": "mean",
  "optimiser_epsilon": 1e-4,


  "init_checkpoint": "",
  "report_directory": "./report",
  "variable_filter": "",
  "checkpoint_path": "./checkpoint/phase1",
  "checkpoint_model": "./checkpoint/phase1/model",
  "logs_path": "./logs/",
  "compile_only": false,
  "fix_synth_seed": true
}
